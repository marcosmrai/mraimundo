+++
title = "Enforcing Fairness Using Ensemble of Diverse Pareto-optimal Models"
date = "2023-09-01"
featured = false
authors = ["Vit√≥ria Guardieiro", "Marcos M Raimundo", "Jorge Poco"]
publication_types = ["1"]
publication = "Data Mining and Knowledge Discovery"
volume = "37"
issue = "5"
pages = "1930-1958"
publisher = "Springer US"
publication_short = ""
abstract = "One of the main challenges of machine learning is to ensure that its applications do not generate or propagate unfair discrimination based on sensitive characteristics such as gender, race, and ethnicity. Research in this area typically limits models to a level of discrimination quantified by an equity metric (usually the 'benefit' discrepancy between privileged and non-privileged groups). However, when models reduce bias, they may also reduce their performance (e.g., accuracy, F1 score). Therefore, we have to optimize contradictory metrics (performance and fairness) at the same time. This problem is well characterized as a multi-objective optimization (MOO) problem. In this study, we use MOO methods to minimize the difference between groups, maximize the benefits for each group, and preserve performance. We search for the best trade-off models in binary classification problems and aggregate them using diverse Pareto-optimal solutions to enforce fairness while maintaining high performance."
image_preview = ""
selected = false
projects = ['mol', 'ethicalai']
math = false
highlight = true
[header]
image = ""
caption = ""
+++
